import org.apache.spark.SparkConf
import org.apache.spark.sql.SparkSession
import org.apache.log4j.Level
import org.apache.log4j.Logger
import org.apache.spark.sql.Dataset
import org.apache.spark.sql.functions._
import org.apache.spark.sql.Row

case class Person(name:String,age:Int,city:String)

object weeek12_add_onemorecolumn extends App {
  Logger.getLogger("org").setLevel(Level.ERROR)
  
  def ageCheck(age:Int):String={
    if(age>18) "Y" else "N"
  }
  
  def cityCheck(city:String):String={
    if(city=="bangalore") "Y" else "N" 
  }
  val sparkConf = new SparkConf()
  sparkConf.set("spark.app.name","my first appication")
  sparkConf.set("spark.master","local[2]")
  
  val spark = SparkSession.builder()
  .config(sparkConf)
  .getOrCreate()
  
  val df = spark.read
  .format("csv")
  .option("inferSchema",true)
  .option("path","G:/shared/spark_data_set/dataset.dataset1")
  .load()
  import spark.implicits._
  val df1:Dataset[Row] = df.toDF("name","age","city")
  
  /* register function in way1 */
  val parseAgeFunction = udf(ageCheck(_:Int):String)
  val parseCityFunction = udf(cityCheck(_:String):String)
  val df2 =df1.withColumn("adult",parseAgeFunction(col("age")))
  //df2.show()
  
  //extra functions 
  val df3= df2.withColumn("Isbanglore",parseCityFunction(col("city")))
  df3.show()
   spark.stop()
}
